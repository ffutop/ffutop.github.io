<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Java on Utop's Blog</title><link>https://www.ffutop.com/tags/java/</link><description>Recent content in Java on Utop's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cmn-Hans-CN</language><lastBuildDate>Sat, 26 Jul 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://www.ffutop.com/tags/java/index.xml" rel="self" type="application/rss+xml"/><item><title>告别 Spring Boot 慢启动：GraalVM 原生镜像迁移实践</title><link>https://www.ffutop.com/posts/2025-07-26-spring-boot-native-migration-guide/</link><pubDate>Sat, 26 Jul 2025 00:00:00 +0000</pubDate><guid>https://www.ffutop.com/posts/2025-07-26-spring-boot-native-migration-guide/</guid><description>随着云原生和 Serverless 架构的兴起，应用的启动速度、内存占用和打包体积变得至关重要。Spring Boot 3.x 结合 GraalVM Native Image 技术，为 Java 应用提供了“原生编译”这一颠覆</description></item><item><title>剖析 GraalVM Native Image 技术</title><link>https://www.ffutop.com/posts/2025-07-26-graalvm-native-image/</link><pubDate>Sat, 26 Jul 2025 00:00:00 +0000</pubDate><guid>https://www.ffutop.com/posts/2025-07-26-graalvm-native-image/</guid><description>Java 语言凭借其强大的生态系统和“一次编写，到处运行”的跨平台能力，在企业级应用领域保持着长久的生命力。然而，随着云原生和边缘计算时代的到来，传</description></item><item><title>容器内进程的 faketime 热更新</title><link>https://www.ffutop.com/posts/2024-08-06-faketime/</link><pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate><guid>https://www.ffutop.com/posts/2024-08-06-faketime/</guid><description>我们的演示系统，使用 libfaketime 实现了历史时刻的简单复现。鉴于通过反复重启进行来实现 Java 服务的 faketime 重置过于缓慢。故阅读文档并整理了对 faketime 热更新的操作手册。 libfaketime</description></item><item><title>[译] JSR 385 - 计量单位 API 2.0</title><link>https://www.ffutop.com/posts/2023-08-24-jsr-385/</link><pubDate>Thu, 24 Aug 2023 00:00:00 +0000</pubDate><guid>https://www.ffutop.com/posts/2023-08-24-jsr-385/</guid><description>译者序 本文来自 JSR 385: Units of Measurement API 2.0 。翻译了其中核心的部分，舍弃了第 6 节（可选项与依赖）、第 7 节（示例）、第 8 节（相关工作）和第 9 节（FAQ）。 译者</description></item><item><title>时间(Timestamp)、日历(Calendar)与夏令时</title><link>https://www.ffutop.com/posts/2021-03-15-datetime-vs-calendar/</link><pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate><guid>https://www.ffutop.com/posts/2021-03-15-datetime-vs-calendar/</guid><description>&lt;p>一个特殊的日期(&lt;code>1988-04-10&lt;/code>, 字段类型 &lt;code>date&lt;/code>)，从数据库尝试读取却始终抛出异常 &lt;code>HOUR_OF_DAY: 0-&amp;gt;1&lt;/code> 。最初百思不得其解，其后发现这个日期恰好是夏令时的起始日，而后又纠结于 1988 年夏令时“从 04 月 10 日早晨 2 时起，将时针往前拨一小时，即二时变三时”。&lt;/p></description></item><item><title>劫持 Java 应用 HTTP 请求</title><link>https://www.ffutop.com/posts/2020-10-19-hijack-http-req/</link><pubDate>Mon, 19 Oct 2020 00:00:00 +0000</pubDate><guid>https://www.ffutop.com/posts/2020-10-19-hijack-http-req/</guid><description>&lt;h2 id="背景">背景&lt;/h2>
&lt;p>全链路追踪中，针对部分特殊的流量，希望将它引导到特定服务上（这个特定服务不在正常请求的链路上）——问题可以被抽象为解决进程间通信过程中目标进程的选择。&lt;/p>
&lt;p>进程间通信方式很多，本篇只关注 Java 进程间套接字通信下 HTTP 形式的请求劫持，引导特定流量到特定进程。&lt;/p></description></item><item><title>Dubbo Telnet 调试</title><link>https://www.ffutop.com/posts/2020-06-17-dubbo-telnet/</link><pubDate>Wed, 17 Jun 2020 00:00:00 +0000</pubDate><guid>https://www.ffutop.com/posts/2020-06-17-dubbo-telnet/</guid><description>&lt;p>始于 Dubbo 2.0.6 的 Telnet Command 是一个令人兴奋的特性，极大地降低了服务化测试的成本，但是，&lt;a href="http://dubbo.apache.org/zh-cn/docs/user/references/telnet.html">寥寥数行的可怜文档&lt;/a>无形地为使用增加了成本。此前虽然一直在使用 Telnet Command，但基本上是浅尝辄止，字符集的问题、重载方法的错误筛选等，都让我不得不对这个特性敬而远之，无法作为高频的生产力工具。最近，频繁出现的调试需求让我不得不尝试接受并熟悉 Dubbo Telnet Command。&lt;/p>
&lt;p>&lt;em>本文只针对 invoke 命令，基于 Dubbo 版本 2.6.7&lt;/em>&lt;/p>
&lt;p>Dubbo Telnet Command &lt;code>invoke&lt;/code> 命令的一般格式为 &lt;code>invoke &amp;lt;全限定名&amp;gt;.&amp;lt;方法名&amp;gt;(&amp;lt;参数&amp;gt;,...,&amp;lt;参数&amp;gt;)&lt;/code>。其中参数需要能被 JSON 解析，即提取命令中的 &lt;code>&amp;lt;参数&amp;gt;,...,&amp;lt;参数&amp;gt;&lt;/code> 部分，并包装上 &lt;code>[]&lt;/code> 构成 &lt;code>[&amp;lt;参数&amp;gt;,...,&amp;lt;参数&amp;gt;]&lt;/code> ，需要保证这个串是一个合法的 JSON Array。&lt;/p>
&lt;p>本文提供的示例均可在 &lt;a href="https://github.com/ffutop/dubbo-telnet-playground">dubbo-telnet-playground&lt;/a> 中找到。&lt;/p></description></item><item><title>HTTP Large Header Fields Problem</title><link>https://www.ffutop.com/posts/2020-04-11-large-http-header/</link><pubDate>Sat, 11 Apr 2020 00:00:00 +0000</pubDate><guid>https://www.ffutop.com/posts/2020-04-11-large-http-header/</guid><description>&lt;p>&lt;em>首次遇到请求头过大的问题，做个记录。特别是在本次处理陷入了误区，做了太多无谓的猜测&lt;/em>&lt;/p>
&lt;p>请求头过大导致响应错误码 400 (Bad Request)、414 (URI Too Long)、431 (Request Header Fields Too Large) 的情况不多，不过原因和解决方案都是比较清晰的。客户端请求的请求头过大导致超出了服务器支持的缓冲区。如果客户端可控，控制请求头的大小；否则，适当调大服务器配置的缓冲区大小。&lt;/p>
&lt;p>最近生产上碰到了这个问题，颇费了一番功夫。接手问题时得到了几个错误的信息，干扰到了处理的全过程。甚至为此去重读了 NGINX Directive &lt;code>client_header_buffer_size&lt;/code> 和 &lt;code>large_client_header_buffers&lt;/code> 在 1.8.1 版本的实现。&lt;/p>
&lt;p>最原始的问题是：NGINX 接收到了大请求头(4.5k)的请求，最终响应了错误码 400 Bad Request 。&lt;/p>
&lt;p>真实的背景因素包括：&lt;/p>
&lt;ul>
&lt;li>请求链路 NGINX -&amp;gt; k8s nginx ingress -&amp;gt; k8s pods (Tomcat)&lt;/li>
&lt;li>NGINX &lt;code>large_client_header_buffers&lt;/code> 使用了默认配置 &lt;code>4 8k&lt;/code>。&lt;/li>
&lt;li>Tomcat maxHttpHeaderSize 使用了默认配置 (default 8192)&lt;/li>
&lt;/ul></description></item><item><title>基于DNS的数据库切换·事故</title><link>https://www.ffutop.com/posts/2020-02-28-db-transfer-based-on-dns/</link><pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate><guid>https://www.ffutop.com/posts/2020-02-28-db-transfer-based-on-dns/</guid><description>&lt;p>我们生产环境上所有的应用都是通过域名来访问 MySQL、Redis 等基础服务。按说域名相较于 IP，凭空多了个 DNS 解析动作，是一个劣化的方案。但好处在于，一旦需要切换基础服务，将带来巨大的利好。可是，任何忽视DNS Record TTL的切换方案，都将伴随着巨大的风险。甚至，成为否定该利好的佐证。&lt;/p></description></item><item><title>GroovyClassLoader 引发的 FullGC</title><link>https://www.ffutop.com/posts/2019-11-07-groovyclassloader-fullgc/</link><pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate><guid>https://www.ffutop.com/posts/2019-11-07-groovyclassloader-fullgc/</guid><description>&lt;h2 id="背景">背景&lt;/h2>
&lt;p>近日，一个线上应用的存活探针频繁报警。几分钟内 Full GC 次数暴涨上百次，&lt;strong>stop the world&lt;/strong> :&amp;lt; 从 &lt;code>gc.log&lt;/code> 中，看到的原因是触及了 &lt;code>Metaspace&lt;/code> 的阈值，进而引发了 FGC。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-plain" data-lang="plain">&lt;span style="display:flex;">&lt;span>2019-11-05T14:31:38.880+0800: 504600.716: [Full GC (Metadata GC Threshold) 2019-11-05T14:31:38.880+0800: 504600.716: [CMS2019-11-05T14:31:39.364+0800: 504601.201: [CMS-concurrent-mark: 0.485/0.488 secs] [Times: user=0.48 sys=0.00, real=0.49 secs]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> (concurrent mode failure): 266828K-&amp;gt;266865K(873856K), 1.3752377 secs] 267430K-&amp;gt;266865K(1267072K), [Metaspace: 204152K-&amp;gt;204152K(1267712K)], 1.3757441 secs] [Times: user=1.36 sys=0.00, real=1.38 secs]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>2019-11-05T14:31:40.256+0800: 504602.092: [Full GC (Last ditch collection) 2019-11-05T14:31:40.256+0800: 504602.092: [CMS: 266865K-&amp;gt;266841K(873856K), 0.8590901 secs] 266865K-&amp;gt;266841K(1267072K), [Metaspace: 204152K-&amp;gt;204152K(1267712K)], 0.8595047 secs] [Times: user=0.86 sys=0.00, real=0.86 secs]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>2019-11-05T14:31:41.117+0800: 504602.953: [Full GC (Metadata GC Threshold) 2019-11-05T14:31:41.117+0800: 504602.953: [CMS: 266841K-&amp;gt;266816K(873856K), 0.9109948 secs] 267218K-&amp;gt;266816K(1267072K), [Metaspace: 204153K-&amp;gt;204153K(1267712K)], 0.9114975 secs] [Times: user=0.91 sys=0.00, real=0.91 secs]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>2019-11-05T14:31:42.028+0800: 504603.865: [Full GC (Last ditch collection) 2019-11-05T14:31:42.028+0800: 504603.865: [CMS: 266816K-&amp;gt;266769K(873856K), 1.0351283 secs] 266816K-&amp;gt;266769K(1267072K), [Metaspace: 204153K-&amp;gt;204153K(1267712K)], 1.0355630 secs] [Times: user=0.92 sys=0.00, real=1.04 secs]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>FGC 前后，&lt;code>Metaspace&lt;/code> 占用的内存没有得到任何释放。&lt;em>[Metaspace: 204153K-&amp;gt;204153K(1267712K)]&lt;/em> 。这也就是反复 FGC 的原因。&lt;/p></description></item></channel></rss>