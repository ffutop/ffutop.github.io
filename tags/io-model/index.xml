<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>IO Model on Utop's Blog</title><link>https://www.ffutop.com/tags/io-model/</link><description>Recent content in IO Model on Utop's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cmn-Hans-CN</language><lastBuildDate>Tue, 05 Mar 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://www.ffutop.com/tags/io-model/index.xml" rel="self" type="application/rss+xml"/><item><title>理解 Linux Kernel (9) - IO Multiplexing</title><link>https://www.ffutop.com/posts/2019-03-05-understand-kernel-9/</link><pubDate>Tue, 05 Mar 2019 00:00:00 +0000</pubDate><guid>https://www.ffutop.com/posts/2019-03-05-understand-kernel-9/</guid><description>&lt;p>&lt;a href="./2019-01-15-understand-Kernel-8/">前一篇&lt;/a>已经对 Linux 内核网络相关的内容进行了基础性的介绍。数据从到达网卡，到最终被用户进程获取，最少经过了三个进程/硬中断的配合：网络中断负责将网络接收到的数据读取到内存并添加到 softnet_data 队列，并设置软中断通知内核进程 ksoftirqd；内核进程 ksoftirqd 被调度并处于运行状态，处理位于 softnet_data 中的 &lt;code>struct sock&lt;/code> 对象，将其逐级从网络接口层逐级提升到网络层、传输层&amp;hellip;最终添加到接收队列 &lt;code>sk_receive_queue&lt;/code> 中；用户进程通过 &lt;code>read&lt;/code>、&lt;code>recv&lt;/code>、&lt;code>recvfrom&lt;/code> 等命令检查并获取 &lt;code>sk_receive_queue&lt;/code> 中的数据。&lt;/p>
&lt;p>整个流程从概述上可以很轻松地配合进行网络数据交互，但如果要监控多个网络套接字呢？处理流程将变得复杂。我们无法预知哪个套接字能优先接收到数据。因此，最直接的办法就是轮询，在用户程序硬编码，通过设置超时时间的方式尝试获取数据。当然，这个效率就相当低下了。每次试探都需要触发系统调用（要知道这代价可是相当大的），另外超时时间的设置也是一个硬性的阻塞式消耗。&lt;/p>
&lt;p>那么，有没有解决方案呢？当然有。通过用户程序硬编码式的轮询显然是陷入性能瓶颈的根源。因此内核主动提供了轮询式的系统调用（&lt;code>select&lt;/code>, &lt;code>poll&lt;/code>, &lt;code>epoll&lt;/code>）。通过将轮询逻辑下沉到内核态，系统调用就只会有一次，而且超时时间的设置也显得统一。本篇就要就 &lt;code>select&lt;/code> 和 &lt;code>epoll&lt;/code> 两类系统调用的实现进行探究。&lt;/p></description></item></channel></rss>